{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Title: Chapter 10 Solutions\n",
    "\n",
    "Date: April 27, 2023\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is \"self-supervised learning\"?\n",
    "    - <span style=\"color:blue\">Self-supervising learning is when training a model where the labels are embedded in the independent variable, rather than requiring external labels. </span>\n",
    "2. What is a \"language model\"?\n",
    "    - <span style=\"color:blue\">A language model is a model that has been trained to guess the next word in a text after reading the ones before. </span>\n",
    "3. Why is a language model considered self-supervised?\n",
    "    - <span style=\"color:blue\">We do not give labels to our model. Instead we feed it lots of texts and it is able to automatically get the labels from the data. </span>\n",
    "4. What are self-supervised models usually used for?\n",
    "    - <span style=\"color:blue\">These models are usually used for pretraining a model used for transfer learning. </span>\n",
    "5. Why do we fine-tune language models?\n",
    "    - <span style=\"color:blue\">While the pretrained model may know the basics of the language we are using in the task, it helps to get used to the style of the corpus we are targeting. In the case of the IMDb dataset, there will be lots of names of movie directors and actors, and often a less formal style of language than that seen in Wikipedia. </span>\n",
    "6. What are the three steps to create a state-of-the-art text classifier?\n",
    "    - <span style=\"color:blue\">1)  The LM is trained on a general-domain corpus to capture\n",
    "general features of the language in different layers. 2) Fine-tune the LM on data of the target task so it adapts to the idiosyncracies of the target data. 3) Fine-tune the LM as a text classifier. </span>\n",
    "7. How do the 50,000 unlabeled movie reviews help us create a better text classifier for the IMDb dataset?\n",
    "    - <span style=\"color:blue\">By fine-tuning the pretraining language model (already trained on Wikipedia articles), this LM will become particularly good at predicting the next word of a movie review. For it to improve in predicting the next word of a text, it will need a better understanding of the language style and structure of the text the IMDb dataset, which will in turn help it perform better as a text classifier. </span>\n",
    "\n",
    "8. What are the three steps to prepare your data for a language model?\n",
    "    - <span style=\"color:blue\">Tokenization, numericalization and language model data loader </span>\n",
    "9. What is \"tokenization\"? Why do we need it?\n",
    "    - <span style=\"color:blue\">A deep learning model expects numbers as inputs, not English words so we need to convert the text into a list of words through tokenization. </span>\n",
    "10. Name three different approaches to tokenization.\n",
    "    - <span style=\"color:blue\">1) Word-based: split a sentence on spaces and applying language-specific rules to try to separate parts of meaning even when there are no spaces (i.e. \"don't\" into \"do n't\") 2) Subword based: split words into samller parts 3) split a sentence into its individual characters </span>\n",
    "11. What is `xxbos`?\n",
    "    - <span style=\"color:blue\">A special token that indicates the start of a new text. </span>\n",
    "12. List four rules that fastai applies to text during tokenization.\n",
    "    - <span style=\"color:blue\">text </span>\n",
    "13. Why are repeated characters replaced with a token showing the number of repetitions and the character that's repeated?\n",
    "14. What is \"numericalization\"?\n",
    "15. Why might there be words that are replaced with the \"unknown word\" token?\n",
    "16. With a batch size of 64, the first row of the tensor representing the first batch contains the first 64 tokens for the dataset. What does the second row of that tensor contain? What does the first row of the second batch contain? (Carefulâ€”students often get this one wrong! Be sure to check your answer on the book's website.)\n",
    "17. Why do we need padding for text classification? Why don't we need it for language modeling?\n",
    "18. What does an embedding matrix for NLP contain? What is its shape?\n",
    "19. What is \"perplexity\"?\n",
    "20. Why do we have to pass the vocabulary of the language model to the classifier data block?\n",
    "21. What is \"gradual unfreezing\"?\n",
    "22. Why is text generation always likely to be ahead of automatic identification of machine-generated texts?\n",
    "    - <span style=\"color:blue\">text </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
